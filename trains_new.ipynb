{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from scipy.sparse import hstack\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_to_df(filename):\n",
    "    df_all=pd.DataFrame(columns=['title','author','institution','year','abstract','label'])\n",
    "    f=open(filename,encoding='utf-8')\n",
    "    i=0\n",
    "    for line in f:\n",
    "        if line!='\\n':\n",
    "            lines=line.split('\\t')\n",
    "            lines[5]=re.sub('\\n','',lines[5])\n",
    "#             print(lines[2])\n",
    "#             print(lines[5])\n",
    "            df_all=df_all.append({'author':lines[0],'abstract':lines[1],'title':lines[2],'institution':lines[3],'year':lines[4],'label':lines[5]},ignore_index=True)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_raw_1=trans_to_df('result2.txt')\n",
    "# df_all_raw_2=trans_to_df('result2.txt')\n",
    "# df_all_raw=pd.concat([df_all_raw_1,df_all_raw_2])\n",
    "\n",
    "df_all=df_all_raw_1\n",
    "df_all=df_all[df_all['abstract']!='An abstract is not available.']\n",
    "df_all=df_all.drop_duplicates()\n",
    "df_all=df_all.reset_index(drop=True)\n",
    "df_all['abstract'] = df_all['abstract']+df_all['title']*5+df_all['author']*5+df_all['institution']*5\n",
    "# print(df_all[df_all['label']=='CIKM'].count())\n",
    "# print(df_all[df_all['label']=='CHI'].count())\n",
    "# print(df_all[df_all['label']=='KDD'].count())\n",
    "# print(df_all[df_all['label']=='SIGIR'].count())\n",
    "# print(df_all[df_all['label']=='SIGCSE'].count())\n",
    "# print(df_all[df_all['label']=='WWW'].count())\n",
    "# print(df_all[df_all['label']=='SIGGRAPH'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even(df1,label):\n",
    "    df_label=df1[df1['label']==label]\n",
    "#     display(df_label)\n",
    "#     df_label=df_label.sample(n=range1,replace = False,random_state=42)\n",
    "    return df_label\n",
    "\n",
    "\n",
    "def nlp_preprocessing(total_text, index, column):\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        # replace every special char with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n",
    "        # replace multiple spaces with single space\n",
    "        total_text = re.sub('\\s+', ' ', total_text)\n",
    "        total_text = re.sub(r\"http\\S+\", \"\", total_text)\n",
    "        # converting all the chars into lower-case.\n",
    "        total_text = total_text.lower()\n",
    "        total_text = re.sub(r\"n\\'t\", \" not\", total_text)\n",
    "        total_text = re.sub(r\"\\'re\", \" are\", total_text)\n",
    "        total_text = re.sub(r\"\\'s\", \" is\", total_text)\n",
    "        total_text = re.sub(r\"\\'d\", \" would\", total_text)\n",
    "        total_text = re.sub(r\"\\'ll\", \" will\", total_text)\n",
    "        total_text = re.sub(r\"\\'t\", \" not\", total_text)\n",
    "        total_text = re.sub(r\"\\'ve\", \" have\", total_text)\n",
    "        total_text = re.sub(r\"\\'m\", \" am\", total_text)\n",
    "#         for sub in set1:\n",
    "#                 total_text = re.sub(sub, \" \", total_text)\n",
    "        for word in total_text.split():\n",
    "            # if the word is a not a stop word then retain that word from the data\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "\n",
    "        df_all[column][index] = string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict1(df_even):\n",
    "\n",
    "    i=0\n",
    "    list_author=[]\n",
    "    list_author1=[]\n",
    "    list_author2=[]\n",
    "    list_author3=[]\n",
    "    list_author4=[]\n",
    "    list_author5=[]\n",
    "    list_author6=[]\n",
    "    sum=0\n",
    "    list_author=df_even['author']\n",
    "    dict1={}\n",
    "    for list_author1 in list_author:\n",
    "        list_author1=list_author1.split(':')\n",
    "        for list_author2 in list_author1:\n",
    "            list_author3.append(list_author2)\n",
    "    list_author4=list(set(list_author3))[1:]\n",
    "    for list_unique_author in list_author4:\n",
    "        for list_author in list_author3:\n",
    "            if list_unique_author== list_author: i+=1\n",
    "        dict1[list_unique_author]=i\n",
    "        i=0\n",
    "    df_even['number_author']=0\n",
    "    df_even['new_author_count']=0\n",
    "    for index, row in df_even.iterrows():\n",
    "        list_author5=row['author'].split(':')\n",
    "        \n",
    "        for list_author6 in list_author5:\n",
    "            \n",
    "            if not(list_author6)=='':\n",
    "                sum=dict1[list_author6]+sum\n",
    "            else:list_author5.remove('')\n",
    "        df_even['number_author'][index]=len(list_author5)\n",
    "        df_even['new_author_count'][index]=sum\n",
    "        sum=0\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took for preprocessing the text : 5.491975099999763 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#text processing stage.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "start_time = time.clock()\n",
    "for index, row in df_all.iterrows():\n",
    "    if type(row['abstract']) is str:\n",
    "        nlp_preprocessing(row['abstract'], index, 'abstract')\n",
    "    else:\n",
    "        print(\"there is no text description for id:\",index)\n",
    "print('Time took for preprocessing the text :',time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIKM 1346\n",
      "CHI 1046\n",
      "KDD 594\n",
      "SIGIR 1125\n",
      "SIGCSE 1240\n",
      "WWW 927\n",
      "siggraph 1189\n"
     ]
    }
   ],
   "source": [
    "print('CIKM',df_all[df_all['label']=='CIKM']['label'].count())\n",
    "print('CHI',df_all[df_all['label']=='CHI']['label'].count())\n",
    "print('KDD',df_all[df_all['label']=='KDD']['label'].count())\n",
    "print('SIGIR',df_all[df_all['label']=='SIGIR']['label'].count())\n",
    "print('SIGCSE',df_all[df_all['label']=='SIGCSE']['label'].count())\n",
    "print('WWW',df_all[df_all['label']=='WWW']['label'].count())\n",
    "print('siggraph',df_all[df_all['label']=='SIGGRAPH']['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "list_datafrme=[]\n",
    "labels=df_all['label'].unique()\n",
    "for label in labels: \n",
    "    i=i+1\n",
    "    df_even=even(df_all,label)\n",
    "    dict1(df_even)\n",
    "    #     display(df_even)\n",
    "    list_datafrme.append(df_even)\n",
    "\n",
    "df_new_all=pd.concat(list_datafrme)\n",
    "df_new_all.reset_index(drop=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_new_all['year'] = df_new_all['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_all.to_csv('train2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>institution</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "      <th>number_author</th>\n",
       "      <th>new_author_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sampling Big Trajectory Data</td>\n",
       "      <td>Yanhua Li:Chi-Yin Chow:Ke Deng:Mingxuan Yuan:J...</td>\n",
       "      <td>Worcester Polytechnic Institute, Worcester, MA...</td>\n",
       "      <td>2015</td>\n",
       "      <td>increasing prevalence sensors mobile devices l...</td>\n",
       "      <td>CIKM</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2882</td>\n",
       "      <td>A Clustering-based Approach to Detect Probable...</td>\n",
       "      <td>Daniel Lemes Gribel:Maira Gatti de Bayser:Leon...</td>\n",
       "      <td>Pontifical Catholic University of Rio de Janei...</td>\n",
       "      <td>2015</td>\n",
       "      <td>numerous lawsuits progress already judged braz...</td>\n",
       "      <td>CIKM</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2883</td>\n",
       "      <td>VizQ: A System for Scalable Processing of Visi...</td>\n",
       "      <td>Arif Arman:Mohammed Eunus Ali:Farhana Murtaza ...</td>\n",
       "      <td>Bangladesh University of Engineering and Techn...</td>\n",
       "      <td>2017</td>\n",
       "      <td>demonstration present vizq efficient scalable ...</td>\n",
       "      <td>CIKM</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2884</td>\n",
       "      <td>Identification of Microblogs Prominent Users d...</td>\n",
       "      <td>Imen Bizid:Nibal Nayef:Patrice Boursier:Sami F...</td>\n",
       "      <td>L3i, University of La Rochelle, La Rochelle, F...</td>\n",
       "      <td>2015</td>\n",
       "      <td>specific real world events users microblogging...</td>\n",
       "      <td>CIKM</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2885</td>\n",
       "      <td>Entity and Aspect Extraction for Organizing Ne...</td>\n",
       "      <td>Radityo Eko Prasojo:Mouna Kacimi:Werner Nutt:</td>\n",
       "      <td>Free University of Bozen-Bolzano, Bozen-Bolzan...</td>\n",
       "      <td>2015</td>\n",
       "      <td>news websites give users opportunity participa...</td>\n",
       "      <td>CIKM</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7462</td>\n",
       "      <td>A graph-theoretic approach to webpage segmenta...</td>\n",
       "      <td>Deepayan Chakrabarti:Ravi Kumar:Kunal Punera:</td>\n",
       "      <td>Yahoo! Research, Sunnyvale, CA, USA:Yahoo! Res...</td>\n",
       "      <td>2008</td>\n",
       "      <td>consider problem segmenting webpage visually s...</td>\n",
       "      <td>WWW</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7463</td>\n",
       "      <td>Fast maximum clique algorithms for large graphs</td>\n",
       "      <td>Ryan A. Rossi:David F. Gleich:Assefaw H. Gebre...</td>\n",
       "      <td>Purdue University, West Lafayette, IN, USA:Pur...</td>\n",
       "      <td>2014</td>\n",
       "      <td>propose fast parallel maximum clique algorithm...</td>\n",
       "      <td>WWW</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7464</td>\n",
       "      <td>Automatic Hierarchical Table of Contents Gener...</td>\n",
       "      <td>Debabrata Mahapatra:Ragunathan Mariappan:Vaibh...</td>\n",
       "      <td>National University of Singapore, Singapore, S...</td>\n",
       "      <td>2018</td>\n",
       "      <td>number freely available online educational vid...</td>\n",
       "      <td>WWW</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7465</td>\n",
       "      <td>Extrapolation methods for accelerating PageRan...</td>\n",
       "      <td>Sepandar D. Kamvar:Taher H. Haveliwala:Christo...</td>\n",
       "      <td>Stanford University, Stanford, CA:Stanford Uni...</td>\n",
       "      <td>2003</td>\n",
       "      <td>present novel algorithm fast computation pager...</td>\n",
       "      <td>WWW</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7466</td>\n",
       "      <td>Email Category Prediction</td>\n",
       "      <td>Aston Zhang:Lluis Garcia-Pueyo:James B. Wendt:...</td>\n",
       "      <td>University of Illinois at Urbana-Champaign, Ch...</td>\n",
       "      <td>2017</td>\n",
       "      <td>according recent estimates 90 consumer receive...</td>\n",
       "      <td>WWW</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7467 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          Sampling Big Trajectory Data   \n",
       "2882  A Clustering-based Approach to Detect Probable...   \n",
       "2883  VizQ: A System for Scalable Processing of Visi...   \n",
       "2884  Identification of Microblogs Prominent Users d...   \n",
       "2885  Entity and Aspect Extraction for Organizing Ne...   \n",
       "...                                                 ...   \n",
       "7462  A graph-theoretic approach to webpage segmenta...   \n",
       "7463    Fast maximum clique algorithms for large graphs   \n",
       "7464  Automatic Hierarchical Table of Contents Gener...   \n",
       "7465  Extrapolation methods for accelerating PageRan...   \n",
       "7466                          Email Category Prediction   \n",
       "\n",
       "                                                 author  \\\n",
       "0     Yanhua Li:Chi-Yin Chow:Ke Deng:Mingxuan Yuan:J...   \n",
       "2882  Daniel Lemes Gribel:Maira Gatti de Bayser:Leon...   \n",
       "2883  Arif Arman:Mohammed Eunus Ali:Farhana Murtaza ...   \n",
       "2884  Imen Bizid:Nibal Nayef:Patrice Boursier:Sami F...   \n",
       "2885      Radityo Eko Prasojo:Mouna Kacimi:Werner Nutt:   \n",
       "...                                                 ...   \n",
       "7462      Deepayan Chakrabarti:Ravi Kumar:Kunal Punera:   \n",
       "7463  Ryan A. Rossi:David F. Gleich:Assefaw H. Gebre...   \n",
       "7464  Debabrata Mahapatra:Ragunathan Mariappan:Vaibh...   \n",
       "7465  Sepandar D. Kamvar:Taher H. Haveliwala:Christo...   \n",
       "7466  Aston Zhang:Lluis Garcia-Pueyo:James B. Wendt:...   \n",
       "\n",
       "                                            institution  year  \\\n",
       "0     Worcester Polytechnic Institute, Worcester, MA...  2015   \n",
       "2882  Pontifical Catholic University of Rio de Janei...  2015   \n",
       "2883  Bangladesh University of Engineering and Techn...  2017   \n",
       "2884  L3i, University of La Rochelle, La Rochelle, F...  2015   \n",
       "2885  Free University of Bozen-Bolzano, Bozen-Bolzan...  2015   \n",
       "...                                                 ...   ...   \n",
       "7462  Yahoo! Research, Sunnyvale, CA, USA:Yahoo! Res...  2008   \n",
       "7463  Purdue University, West Lafayette, IN, USA:Pur...  2014   \n",
       "7464  National University of Singapore, Singapore, S...  2018   \n",
       "7465  Stanford University, Stanford, CA:Stanford Uni...  2003   \n",
       "7466  University of Illinois at Urbana-Champaign, Ch...  2017   \n",
       "\n",
       "                                               abstract label  number_author  \\\n",
       "0     increasing prevalence sensors mobile devices l...  CIKM              8   \n",
       "2882  numerous lawsuits progress already judged braz...  CIKM              3   \n",
       "2883  demonstration present vizq efficient scalable ...  CIKM              4   \n",
       "2884  specific real world events users microblogging...  CIKM              5   \n",
       "2885  news websites give users opportunity participa...  CIKM              3   \n",
       "...                                                 ...   ...            ...   \n",
       "7462  consider problem segmenting webpage visually s...   WWW              3   \n",
       "7463  propose fast parallel maximum clique algorithm...   WWW              4   \n",
       "7464  number freely available online educational vid...   WWW              3   \n",
       "7465  present novel algorithm fast computation pager...   WWW              4   \n",
       "7466  according recent estimates 90 consumer receive...   WWW              5   \n",
       "\n",
       "      new_author_count  \n",
       "0                   18  \n",
       "2882                 3  \n",
       "2883                 4  \n",
       "2884                 6  \n",
       "2885                 5  \n",
       "...                ...  \n",
       "7462                15  \n",
       "7463                 7  \n",
       "7464                 3  \n",
       "7465                 4  \n",
       "7466                12  \n",
       "\n",
       "[7467 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
